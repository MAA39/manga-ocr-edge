# ノベライズプロンプトの変遷と設計意図

本ドキュメントでは、`POST /novel` エンドポイントにおけるプロンプトの改善履歴、変更理由、およびその効果について記録します。

## 概要: なぜプロンプトを変え続けるのか？
Llama 3.2 Visionのようなマルチモーダルモデルは、画像の解釈能力は高いものの、出力形式（言語や文体）の制御には繊細な指示が必要です。
特に「漫画から小説へ」というタスクでは、以下の3つの壁にぶつかりました。

1.  **言語の壁**: プロンプトを英語にすると、出力まで英語になってしまう。
2.  **表現の壁**: 「Show, Don't Tell」の概念を理解させないと、ただの状況説明（キャプション）になってしまう。
3.  **不自然さの壁**: 英語の概念をそのまま訳すと、「顎が引き締まる」のような翻訳調（Translationese）の日本語になってしまう。

---

## 変遷履歴

### Phase 1: 初期の単純な指示
**実装:** 「この画像を小説のように詳細に描写してください」
**結果:** ❌ 失敗
- 出力が短すぎる。
- 漫符（汗や青筋）を無視する、あるいは「顔にマークがある」と物理的に描写してしまう。

### Phase 2: Deep Researchに基づく構造化（英語プロンプト）
**変更点:**
- 作家ペルソナ（Award-winning novelist）を追加。
- Show, Don't Tell ルール（感情ラベル禁止）を追加。
- 漫符翻訳ルール（汗→焦り）を追加。
- 指示自体を**英語**で記述（モデルの推論能力を最大化するため）。

**結果:** ❌ 部分的失敗
- 内容の質は上がった（身体的描写が増えた）。
- **致命的な問題:** 指示が英語であることに引きずられ、出力も**英語**になってしまった。
- `YOU MUST OUTPUT IN JAPANESE` と強調しても、英語が出力されるケースが多発。

### Phase 3: 全日本語化と翻訳調の排除 (Current)
**変更点:**
- プロンプトの指示言語をすべて**日本語**に戻した（出力言語の固定化）。
- 「顎が引き締まる (Jaw tightened)」のような不自然な直訳表現を削除。
- 代わりに、「奥歯を噛み締める」「眉間に皺を刻む」といった**自然な日本語の慣用句**を例として提示。

**プロンプト差分 (Diff):**

```diff
- 1. **Show, Don't Tell**: Do not use simple emotional labels. Describe physical reactions (e.g., "His jaw tightened").
+ 1. **Show, Don't Tell（語るな、見せろ）**:
+    - 悪い例：「彼は怒っていた」
+    - 良い例：「彼は奥歯をギリリと噛み締め、拳を震わせた」

- 2. **Translate Visual Symbols**:
-    - Vein pop (💢) -> Describe as gritting teeth or pulsing temples.
+ 2. **漫符（Visual Symbols）の自然な翻訳**:
+    - 青筋 (💢) -> 「額に青筋を浮かべる」「こめかみがピクリと跳ねる」など、抑えきれない怒りとして描く。

- 3. **Language**: YOU MUST OUTPUT THE STORY IN **JAPANESE**.
+ 3. **言語と文体**:
+    - **自然な日本語の小説**として書いてください。翻訳調は避けてください。
```

## 今後の課題と展望 (User Feedback: "うーんて感じ")
現在のプロンプトでも、まだAI特有の「繰り返し」や「唐突な展開」が見られます（例：ナノバナナのテキストで「ナノバナナは...」が連呼される）。

**次のステップの案:**
1.  **Few-Shot Prompting**: 実際の「漫画画像」と「理想的な小説テキスト」のペアを例としてプロンプトに含める（トークン消費は増えるが、文体模写の精度は劇的に上がる）。
2.  **パイプライン処理**: 一度「プロット（あらすじ）」を出力させ、それを元に本文を書かせる2段階構成にする。

### Phase 4: Reverse Adaptation（逆コミカライズ）への挑戦 (Planned)
**コンセプト:**
漫画を「説明」するのではなく、漫画の「原作となった架空の小説」を**再構築**（Reverse Engineering）するというアプローチ。
AIに「あなたはこの漫画の原作者である」という役割を与え、以下の制約を課す。

**主な戦略:**
1.  **原作者ペルソナ**: 「絵を見ている人」ではなく「物語を生み出した人」として振る舞わせる。
2.  **メタ要素の排除**: 「コマ」「吹き出し」「背景」といった漫画媒体の用語を禁止。
3.  **情報の解凍**: 漫画で省略された情報（気温、匂い、触感）を、小説形式に戻す際に補完させる。

このアプローチにより、「絵の説明」から完全に脱却し、純粋な「小説」としての出力を目指す。

**結果: ❌ 失敗 (Looping & Incomplete)**
- **テスト対象**: 起承転結のはっきりした4コマ漫画（猫のプログラマがバグに苦しみ、最後は寝落ちして解決）。
- **出力**:
  - 文体は「暗い夜」「静寂の海」といった小説的なトーンが出せた。
  - **問題点**: 文章が途中からループし始め（「画面のメッセージを聞き続けていました...」）、4コマ目のオチ（解決）まで辿り着けなかった。
- **分析**:
  - Llama 3.2 Vision (11B) にとって、複数のコマを時系列順に正しく認識し、それを物語として完結させるタスクは負荷が高すぎる可能性がある。
  - 特に「画像全体の情報を保持しつつ、文章の構成を考える」ことが難しい。

**結論:**
この「逆コミカライズ」を実現するには、単一のプロンプトでは限界がある。
- **コマ分割**: 前処理で画像をコマごとに分割し、個別に描写させる。
- **プロット生成**: まず全体の大まかな流れ（あらすじ）を出力させ、それをガイドにして本文を書かせる。
といった「パイプライン処理」が必須であると判明した。
