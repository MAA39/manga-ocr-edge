# 技術スタックとコアテクノロジー

## 1. Cloudflare Workers (ランタイム)

### 選定理由
漫画の画像処理には低レイテンシが求められます。従来のサーバーレス（AWS Lambda）は「コールドスタート」（最初のリクエスト時の遅延）が発生しがちで、EC2/VPSは継続的な管理と待機コストが必要です。
Cloudflare WorkersはV8 Isolateモデルを使用しており、秒単位ではなくミリ秒単位でインスタンスを生成できます。しかも、ユーザーに最も近いエッジロケーションで動作します。

-   **ゼロ・コールドスタート**: ユーザーが画像をアップロード → 即座に処理開始。
-   **エッジロケーション**: 日本のユーザーに対しては東京や大阪でコードが動き、ネットワーク遅延を最小化します。
-   **コストモデル**: 稼働時間ではなくリクエスト数課金です。

## 2. Hono (フレームワーク)

### 選定理由
`wrangler` CLI は基本的なワーカーを生成しますが、ルーティングやリクエスト処理には **Hono** を採用しました。

-   **Web標準準拠**: 標準的なWeb API (Request/Response) オブジェクトを使用します。
-   **TypeScriptファースト**: `Env` や `Bindings` の型定義が優れており、型安全な開発が可能です。
-   **超軽量**: Node.jsの組み込み機能に依存しないため、軽量なWorkersランタイムに最適です。
-   **ミドルウェア**: 今後CORSや認証、ログ出力を追加するのも容易です。

## 3. Workers AI & Llama 3.2 Vision (頭脳)

### モデル: `@cf/meta/llama-3.2-11b-vision-instruct`
これは、テキストと画像の両方を理解できるマルチモーダルモデルです。

-   **マルチモーダル**: 画像配列とテキストプロンプトを同時に受け入れられます。
-   **OCR能力**: 文字をただ吐き出すだけの従来のOCR（Tesseract等）とは異なり、Llama 3.2はコンテキスト（例：「吹き出しの文字だけを抽出して」）を「理解」できます。
-   **マネージド推論**: GPUやCUDAドライバを管理する必要はありません。`env.AI.run()` を呼ぶだけです。

### 統合方法
やり取りは "Bindings"（バインディング）を通じて行われます。
`wrangler.jsonc` にて設定します：
```jsonc
"ai": {
  "binding": "AI"
}
```
これにより、Honoのコンテキスト (`c.env.AI`) で `AI` オブジェクトが利用可能になり、リクエストハンドラ内から直接推論を呼び出すことができます。
